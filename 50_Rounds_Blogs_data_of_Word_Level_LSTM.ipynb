{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "50 Rounds Blogs data of Word Level LSTM.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niranjan-sa/NLP/blob/master/50_Rounds_Blogs_data_of_Word_Level_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljJTtmtqA2D4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "d3a6ab92-bf8d-4ddc-cd3e-bd35de1062eb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "import os\n",
        "print(os.listdir('../gdrive/My Drive/NLP/Final Project/'))\n",
        "os.chdir('../gdrive/My Drive/NLP/Final Project/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "['data', 'NLP Projects.gdoc', 'LSTM', 'weights-improvement-01-2.5720-bigger.hdf5', 'weights-improvement-02-2.3190-bigger.hdf5', 'weights-improvement-03-2.1558-bigger.hdf5', 'weights-improvement-04-2.0431-bigger.hdf5', 'weights-improvement-05-1.9590-bigger.hdf5', 'weights-improvement-06-1.8898-bigger.hdf5', 'weights-improvement-07-1.8352-bigger.hdf5', 'weights-improvement-08-1.7884-bigger.hdf5', 'weights-improvement-09-1.7428-bigger.hdf5', 'weights-improvement-10-1.7046-bigger.hdf5', 'model.h5', 'weights-improvement-01-2.7923-bigger.hdf5', 'weights-improvement-02-2.4451-bigger.hdf5', 'weights-improvement-03-2.2442-bigger.hdf5', 'weights-improvement-04-2.1141-bigger.hdf5', 'weights-improvement-05-2.0164-bigger.hdf5', 'weights-improvement-06-1.9374-bigger.hdf5', 'weights-improvement-07-1.8761-bigger.hdf5', 'weights-improvement-08-1.8270-bigger.hdf5', 'weights-improvement-09-1.7808-bigger.hdf5', 'weights-improvement-10-1.7414-bigger.hdf5', 'model_10.h5', 'model.json', 'Data Cleaning.ipynb', 'requirements.txt', 'req1.txt', 'req.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuPdxkZ6X1GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = 'data/en_US.blogs.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxKACktEhNQL",
        "colab_type": "code",
        "outputId": "32ee09c3-4a4c-4e16-fc92-1a5aa2139aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "sequences[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [30, 1614, 5, 26, 1, 163, 2, 2549, 2550, 35, 44, 2871, 3, 28],\n",
              " [568, 44, 3940, 4907, 21, 37, 1062, 73, 235, 73, 248, 13],\n",
              " [2551, 163, 73, 157, 1, 379, 2, 1, 286, 264, 1178, 1325],\n",
              " [28, 30, 1614, 13, 3323, 35, 2552, 264, 1404],\n",
              " [],\n",
              " [],\n",
              " [2069, 1, 227],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7Df-vKhpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = [item for sublist in sequences for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAOOpT55jARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 3\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(flat_list) - seq_length, 1):\n",
        "\tseq_in = flat_list[i:i + seq_length]\n",
        "\tseq_out = flat_list[i + seq_length]\n",
        "\tdataX.append(seq_in)\n",
        "\tdataY.append(seq_out)\n",
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTpNMayajlYe",
        "colab_type": "code",
        "outputId": "9b441606-e576-4308-88aa-dfb08a5fc446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_patterns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_Ba1MRjlNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX = array(dataX)\n",
        "dataY = array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqbJSLSj9aw",
        "colab_type": "code",
        "outputId": "d5a7ed9e-133b-4c1d-f3f0-105c5e08d76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataX.shape, dataY.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((221274, 3), (221274,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQJLFWPbqbl",
        "colab_type": "code",
        "outputId": "5732016e-53c0-437d-9806-279ab0684379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# separate into input and output\n",
        "X, y = dataX, dataY\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = dataX.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=100)\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 3, 50)             551800    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 3, 100)            60400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11036)             1114636   \n",
            "=================================================================\n",
            "Total params: 1,817,336\n",
            "Trainable params: 1,817,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "221274/221274 [==============================] - 172s 776us/step - loss: 6.3944 - acc: 0.0771\n",
            "Epoch 2/100\n",
            "221274/221274 [==============================] - 167s 753us/step - loss: 5.8526 - acc: 0.1191\n",
            "Epoch 3/100\n",
            "221274/221274 [==============================] - 169s 762us/step - loss: 5.4825 - acc: 0.1509\n",
            "Epoch 4/100\n",
            "221274/221274 [==============================] - 170s 769us/step - loss: 5.2394 - acc: 0.1696\n",
            "Epoch 5/100\n",
            "221274/221274 [==============================] - 169s 765us/step - loss: 5.0610 - acc: 0.1821\n",
            "Epoch 6/100\n",
            "221274/221274 [==============================] - 169s 763us/step - loss: 4.9111 - acc: 0.1906\n",
            "Epoch 7/100\n",
            "221274/221274 [==============================] - 171s 773us/step - loss: 4.7719 - acc: 0.1987\n",
            "Epoch 8/100\n",
            "221274/221274 [==============================] - 167s 755us/step - loss: 4.6375 - acc: 0.2051\n",
            "Epoch 9/100\n",
            "221274/221274 [==============================] - 169s 764us/step - loss: 4.5107 - acc: 0.2115\n",
            "Epoch 10/100\n",
            "221274/221274 [==============================] - 168s 759us/step - loss: 4.3889 - acc: 0.2173\n",
            "Epoch 11/100\n",
            "221274/221274 [==============================] - 167s 755us/step - loss: 4.2727 - acc: 0.2234\n",
            "Epoch 12/100\n",
            "221274/221274 [==============================] - 166s 749us/step - loss: 4.1606 - acc: 0.2302\n",
            "Epoch 13/100\n",
            "221274/221274 [==============================] - 165s 745us/step - loss: 4.0533 - acc: 0.2370\n",
            "Epoch 14/100\n",
            "221274/221274 [==============================] - 169s 765us/step - loss: 3.9511 - acc: 0.2448\n",
            "Epoch 15/100\n",
            "221274/221274 [==============================] - 169s 762us/step - loss: 3.8554 - acc: 0.2540\n",
            "Epoch 16/100\n",
            "221274/221274 [==============================] - 168s 759us/step - loss: 3.7662 - acc: 0.2630\n",
            "Epoch 17/100\n",
            "221274/221274 [==============================] - 169s 764us/step - loss: 3.6830 - acc: 0.2734\n",
            "Epoch 18/100\n",
            "221274/221274 [==============================] - 169s 762us/step - loss: 3.6062 - acc: 0.2823\n",
            "Epoch 19/100\n",
            "221274/221274 [==============================] - 166s 748us/step - loss: 3.5349 - acc: 0.2914\n",
            "Epoch 20/100\n",
            "221274/221274 [==============================] - 169s 763us/step - loss: 3.4702 - acc: 0.2999\n",
            "Epoch 21/100\n",
            "221274/221274 [==============================] - 166s 749us/step - loss: 3.4071 - acc: 0.3087\n",
            "Epoch 22/100\n",
            "221274/221274 [==============================] - 166s 751us/step - loss: 3.3495 - acc: 0.3172\n",
            "Epoch 23/100\n",
            "221274/221274 [==============================] - 167s 754us/step - loss: 3.2946 - acc: 0.3241\n",
            "Epoch 24/100\n",
            "221274/221274 [==============================] - 168s 759us/step - loss: 3.2422 - acc: 0.3320\n",
            "Epoch 25/100\n",
            "221274/221274 [==============================] - 166s 750us/step - loss: 3.1945 - acc: 0.3395\n",
            "Epoch 26/100\n",
            "221274/221274 [==============================] - 165s 748us/step - loss: 3.1489 - acc: 0.3460\n",
            "Epoch 27/100\n",
            "221274/221274 [==============================] - 168s 760us/step - loss: 3.1045 - acc: 0.3530\n",
            "Epoch 28/100\n",
            "221274/221274 [==============================] - 167s 755us/step - loss: 3.0602 - acc: 0.3592\n",
            "Epoch 29/100\n",
            "221274/221274 [==============================] - 166s 752us/step - loss: 3.0209 - acc: 0.3654\n",
            "Epoch 30/100\n",
            "221274/221274 [==============================] - 169s 764us/step - loss: 2.9824 - acc: 0.3720\n",
            "Epoch 31/100\n",
            "221274/221274 [==============================] - 169s 762us/step - loss: 2.9482 - acc: 0.3762\n",
            "Epoch 32/100\n",
            "221274/221274 [==============================] - 166s 751us/step - loss: 2.9118 - acc: 0.3833\n",
            "Epoch 33/100\n",
            "221274/221274 [==============================] - 169s 763us/step - loss: 2.8775 - acc: 0.3880\n",
            "Epoch 34/100\n",
            "221274/221274 [==============================] - 166s 750us/step - loss: 2.8463 - acc: 0.3926\n",
            "Epoch 35/100\n",
            "221274/221274 [==============================] - 167s 756us/step - loss: 2.8156 - acc: 0.3980\n",
            "Epoch 36/100\n",
            "221274/221274 [==============================] - 167s 757us/step - loss: 2.7842 - acc: 0.4023\n",
            "Epoch 37/100\n",
            "221274/221274 [==============================] - 168s 760us/step - loss: 2.7563 - acc: 0.4069\n",
            "Epoch 38/100\n",
            "221274/221274 [==============================] - 168s 757us/step - loss: 2.7297 - acc: 0.4115\n",
            "Epoch 39/100\n",
            "221274/221274 [==============================] - 167s 757us/step - loss: 2.7026 - acc: 0.4151\n",
            "Epoch 40/100\n",
            "221274/221274 [==============================] - 166s 749us/step - loss: 2.6762 - acc: 0.4195\n",
            "Epoch 41/100\n",
            "221274/221274 [==============================] - 168s 761us/step - loss: 2.6508 - acc: 0.4242\n",
            "Epoch 42/100\n",
            "137728/221274 [=================>............] - ETA: 1:03 - loss: 2.5887 - acc: 0.4350"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTa1Hhm7eprb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = sequences.reshape((24692, 1)).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RBSpTUogq68",
        "colab_type": "code",
        "outputId": "0e959eb1-d2c2-4a15-9909-83912cdfb003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sequences.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24692,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtqEUoAxg2bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
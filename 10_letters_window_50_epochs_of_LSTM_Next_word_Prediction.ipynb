{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10 letters window 50 epochs of LSTM Next word Prediction.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niranjan-sa/NLP/blob/master/10_letters_window_50_epochs_of_LSTM_Next_word_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbMkpD2LSWhr",
        "colab_type": "text"
      },
      "source": [
        "**LSTM Based N-gram predictor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpuUVK73R-Tv",
        "colab_type": "code",
        "outputId": "a05ee8dd-e34e-4ca2-cf22-7cfa7408ad64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jMI6W_YVpbN",
        "colab_type": "code",
        "outputId": "064a0093-0a77-43c8-a125-44818f09d71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "import os\n",
        "print(os.listdir('../gdrive/My Drive/NLP/Final Project/'))\n",
        "os.chdir('../gdrive/My Drive/NLP/Final Project/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "['data', 'NLP Projects.gdoc', 'Data Cleaning.ipynb', 'LSTM', 'weights-improvement-01-2.5720-bigger.hdf5', 'weights-improvement-02-2.3190-bigger.hdf5', 'weights-improvement-03-2.1558-bigger.hdf5', 'weights-improvement-04-2.0431-bigger.hdf5', 'weights-improvement-05-1.9590-bigger.hdf5', 'weights-improvement-06-1.8898-bigger.hdf5', 'weights-improvement-07-1.8352-bigger.hdf5', 'weights-improvement-08-1.7884-bigger.hdf5', 'weights-improvement-09-1.7428-bigger.hdf5', 'weights-improvement-10-1.7046-bigger.hdf5', 'model.json', 'model.h5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx7cicsGTiDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"LSTM/data.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEDLe1NxVHns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc9R1lVrVL6l",
        "colab_type": "code",
        "outputId": "7a95c477-0740-44fb-e2e5-d5a0c639d42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  144407\n",
            "Total Vocab:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOMUj3GGV82z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 10\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xa-2IJDXxpI",
        "colab_type": "code",
        "outputId": "f8104f1b-d692-4835-cf73-ce4e934a14b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  144397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGWue9swX0oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQykaMQrZKdb",
        "colab_type": "code",
        "outputId": "5bf8e08c-bc7c-4c22-dcbe-86f6a5cbb7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02cB2IJRZLjW",
        "colab_type": "code",
        "outputId": "33b47aa2-c2f3-404d-e673-cf11e408f72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=10, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "144397/144397 [==============================] - 80s 553us/step - loss: 2.7923\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.79227, saving model to weights-improvement-01-2.7923-bigger.hdf5\n",
            "Epoch 2/10\n",
            "144397/144397 [==============================] - 75s 519us/step - loss: 2.4451\n",
            "\n",
            "Epoch 00002: loss improved from 2.79227 to 2.44512, saving model to weights-improvement-02-2.4451-bigger.hdf5\n",
            "Epoch 3/10\n",
            "144397/144397 [==============================] - 75s 517us/step - loss: 2.2442\n",
            "\n",
            "Epoch 00003: loss improved from 2.44512 to 2.24420, saving model to weights-improvement-03-2.2442-bigger.hdf5\n",
            "Epoch 4/10\n",
            "144397/144397 [==============================] - 75s 521us/step - loss: 2.1141\n",
            "\n",
            "Epoch 00004: loss improved from 2.24420 to 2.11412, saving model to weights-improvement-04-2.1141-bigger.hdf5\n",
            "Epoch 5/10\n",
            "144397/144397 [==============================] - 76s 523us/step - loss: 2.0164\n",
            "\n",
            "Epoch 00005: loss improved from 2.11412 to 2.01642, saving model to weights-improvement-05-2.0164-bigger.hdf5\n",
            "Epoch 6/10\n",
            "144397/144397 [==============================] - 75s 518us/step - loss: 1.9374\n",
            "\n",
            "Epoch 00006: loss improved from 2.01642 to 1.93737, saving model to weights-improvement-06-1.9374-bigger.hdf5\n",
            "Epoch 7/10\n",
            "144397/144397 [==============================] - 76s 524us/step - loss: 1.8761\n",
            "\n",
            "Epoch 00007: loss improved from 1.93737 to 1.87614, saving model to weights-improvement-07-1.8761-bigger.hdf5\n",
            "Epoch 8/10\n",
            "144397/144397 [==============================] - 75s 519us/step - loss: 1.8270\n",
            "\n",
            "Epoch 00008: loss improved from 1.87614 to 1.82701, saving model to weights-improvement-08-1.8270-bigger.hdf5\n",
            "Epoch 9/10\n",
            "144397/144397 [==============================] - 76s 523us/step - loss: 1.7808\n",
            "\n",
            "Epoch 00009: loss improved from 1.82701 to 1.78076, saving model to weights-improvement-09-1.7808-bigger.hdf5\n",
            "Epoch 10/10\n",
            "144397/144397 [==============================] - 75s 518us/step - loss: 1.7414\n",
            "\n",
            "Epoch 00010: loss improved from 1.78076 to 1.74144, saving model to weights-improvement-10-1.7414-bigger.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff1c1d06dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsgTgbsKaH8k",
        "colab_type": "code",
        "outputId": "0e2012ca-c39e-47c9-9e5f-c5efeec261c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_10.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtrHwbP0vOYO",
        "colab_type": "code",
        "outputId": "11cd365e-a751-4d69-a6cf-5690746ed067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f6235748710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRGQIeiKCpnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = numpy.random.randint(0, len(dataX)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkgmWQMHFkWr",
        "colab_type": "code",
        "outputId": "786da69a-6b2e-4b19-eb52-bb0377d630b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "start"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67059"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh8bJMElFlJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern = dataX[start]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQKkvRB7FpMR",
        "colab_type": "code",
        "outputId": "1cf63e21-ce53-4f6f-c32d-63512da8f642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(pattern)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxtyk97wFp9J",
        "colab_type": "code",
        "outputId": "4eef60f0-b124-4741-9f1f-8e6587cc75a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for no in pattern:\n",
        "  print (int_to_char[no])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n",
            "n\n",
            "d\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "y\n",
            " \n",
            "w\n",
            "e\n",
            "n\n",
            "t\n",
            " \n",
            "o\n",
            "n\n",
            " \n",
            "f\n",
            "o\n",
            "r\n",
            " \n",
            "s\n",
            "o\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "i\n",
            "l\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            " \n",
            "s\n",
            "i\n",
            "l\n",
            "e\n",
            "n\n",
            "c\n",
            "e\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "a\n",
            "l\n",
            "i\n",
            "c\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "j\n",
            "u\n",
            "s\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "g\n",
            "i\n",
            "n\n",
            "n\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "k\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            ",\n",
            " \n",
            "'\n",
            "n\n",
            "o\n",
            "w\n",
            ",\n",
            " \n",
            "w\n",
            "h\n",
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDa8ed6WGB_7",
        "colab_type": "code",
        "outputId": "e8b3b410-948d-4e4b-b930-a8020756a184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print (pattern)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19, 32, 22, 1, 38, 26, 23, 43, 1, 41, 23, 32, 38, 1, 33, 32, 1, 24, 33, 36, 1, 37, 33, 31, 23, 1, 41, 26, 27, 30, 23, 1, 27, 32, 1, 37, 27, 30, 23, 32, 21, 23, 10, 0, 0, 19, 30, 27, 21, 23, 1, 41, 19, 37, 1, 28, 39, 37, 38, 1, 20, 23, 25, 27, 32, 32, 27, 32, 25, 1, 38, 33, 1, 38, 26, 27, 32, 29, 1, 38, 33, 1, 26, 23, 36, 37, 23, 30, 24, 8, 1, 4, 32, 33, 41, 8, 1, 41, 26, 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_M7cUS7Ghg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patternX = [1]*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsCZl57IGoAq",
        "colab_type": "code",
        "outputId": "5392e011-d36d-4112-8e15-b293fafa5c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "s = 'the '\n",
        "for c in s:\n",
        "  print (char_to_int[c])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38\n",
            "26\n",
            "23\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvaargAQG9xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patternX[-2] = 23\n",
        "patternX[-3] = 26\n",
        "patternX[-4] = 38"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF2BzjFjHLch",
        "colab_type": "code",
        "outputId": "4f1b2e2a-aee7-44b9-cac8-3c83dc1fccb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in patternX]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(5):\n",
        "\tx = numpy.reshape(patternX, (1, len(patternX), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in patternX]\n",
        "\t#print(result)\n",
        "\tsys.stdout.write(result)\n",
        "\tpatternX.append(index)\n",
        "\tpatternX = patternX[1:len(patternX)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\"                                                                             she jorse of the coothei \"\n",
            " on t\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg4cpDeoHhKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}